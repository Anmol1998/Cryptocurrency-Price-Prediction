{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anmol/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time        low       high       open      close      volume\n",
      "0  1528968660  96.580002  96.589996  96.589996  96.580002    9.647200\n",
      "1  1528968720  96.449997  96.669998  96.589996  96.660004  314.387024\n",
      "2  1528968780  96.470001  96.570000  96.570000  96.570000   77.129799\n",
      "3  1528968840  96.449997  96.570000  96.570000  96.500000    7.216067\n",
      "4  1528968900  96.279999  96.540001  96.500000  96.389999  524.539978\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"/home/anmol/Desktop/crypto_data/LTC-USD.csv\", names=[\"time\",\"low\",\"high\",\"open\",\"close\",\"volume\"])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968660    6489.549805        0.587100      96.580002        9.647200   \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "\n",
      "            ETH-USD_close  ETH-USD_volume  BCH-USD_close  BCH-USD_volume  \n",
      "time                                                                      \n",
      "1528968660            NaN             NaN     871.719971        5.675361  \n",
      "1528968720      486.01001       26.019083     870.859985       26.856577  \n",
      "1528968780      486.00000        8.449400     870.099976        1.124300  \n",
      "1528968840      485.75000       26.994646     870.789978        1.749862  \n",
      "1528968900      486.00000       77.355759     870.000000        1.680500  \n"
     ]
    }
   ],
   "source": [
    "main_df=pd.DataFrame()\n",
    "ratios=[\"BTC-USD\",\"LTC-USD\",\"ETH-USD\",\"BCH-USD\"]\n",
    "for ratio in ratios:\n",
    "    dataset=f\"/home/anmol/Desktop/crypto_data/{ratio}.csv\"\n",
    "    df=pd.read_csv(dataset,names=[\"time\",\"low\",\"high\",\"open\",\"close\",\"volume\"])\n",
    "    #print(df.head())\n",
    "    df.rename(columns={\"close\":f\"{ratio}_close\",\"volume\":f\"{ratio}_volume\"},inplace=True)\n",
    "    \n",
    "    df.set_index(\"time\",inplace=True)\n",
    "    df=df[[f\"{ratio}_close\",f\"{ratio}_volume\"]]\n",
    "    #print(df.head())\n",
    "    \n",
    "    if(len(main_df)==0):\n",
    "        main_df=df\n",
    "    else:\n",
    "        main_df=main_df.join(df)\n",
    "\n",
    "print(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN=60\n",
    "FUTURE_PERIOD_PREDICT=3\n",
    "RATIO_TO_PREDICT=\"LTC-USD\"\n",
    "\n",
    "def classify(current,future):\n",
    "    if float(future)>float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968660    6489.549805        0.587100      96.580002        9.647200   \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "\n",
      "            ETH-USD_close  ETH-USD_volume  BCH-USD_close  BCH-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968660            NaN             NaN     871.719971        5.675361   \n",
      "1528968720      486.01001       26.019083     870.859985       26.856577   \n",
      "1528968780      486.00000        8.449400     870.099976        1.124300   \n",
      "1528968840      485.75000       26.994646     870.789978        1.749862   \n",
      "1528968900      486.00000       77.355759     870.000000        1.680500   \n",
      "\n",
      "               future  \n",
      "time                   \n",
      "1528968660  96.500000  \n",
      "1528968720  96.389999  \n",
      "1528968780  96.519997  \n",
      "1528968840  96.440002  \n",
      "1528968900  96.470001  \n"
     ]
    }
   ],
   "source": [
    "main_df['future']=main_df[f\"{RATIO_TO_PREDICT}_close\"].shift(-FUTURE_PERIOD_PREDICT)\n",
    "print(main_df.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future\n",
      "time                                \n",
      "1528968660      96.580002  96.500000\n",
      "1528968720      96.660004  96.389999\n",
      "1528968780      96.570000  96.519997\n",
      "1528968840      96.500000  96.440002\n",
      "1528968900      96.389999  96.470001\n"
     ]
    }
   ],
   "source": [
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future  target\n",
      "time                                        \n",
      "1528968660      96.580002  96.500000       0\n",
      "1528968720      96.660004  96.389999       0\n",
      "1528968780      96.570000  96.519997       0\n",
      "1528968840      96.500000  96.440002       0\n",
      "1528968900      96.389999  96.470001       1\n",
      "1528968960      96.519997  96.400002       0\n",
      "1528969020      96.440002  96.400002       0\n",
      "1528969080      96.470001  96.400002       0\n",
      "1528969140      96.400002  96.400002       0\n",
      "1528969200      96.400002  96.400002       0\n",
      "1528969260      96.400002  96.449997       1\n",
      "1528969320      96.400002  96.419998       1\n",
      "1528969380      96.400002  96.400002       0\n",
      "1528969440      96.449997  96.419998       0\n",
      "1528969500      96.419998  96.570000       1\n"
     ]
    }
   ],
   "source": [
    "main_df['target']=list(map(classify,main_df[f\"{RATIO_TO_PREDICT}_close\"],main_df[\"future\"]))\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\",\"target\"]].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "times=sorted(main_df.index.values)\n",
    "last_5pct=sorted(main_df.index.values)[-int(0.05*len(times))]\n",
    "validation_main_df=main_df[(main_df.index >= last_5pct)]\n",
    "main_df=main_df[main_df.index<last_5pct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df=df.drop('future',1)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col!=\"target\":\n",
    "            df[col]=df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            df[col]=preprocessing.scale(df[col].values)\n",
    "    df.dropna(inplace=True)\n",
    "    sequential_data=[]\n",
    "    prev_days=deque(maxlen=SEQ_LEN)\n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if(len(prev_days)==SEQ_LEN):\n",
    "            sequential_data.append([np.array(prev_days),i[-1]])\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    buys=[]\n",
    "    sells=[]\n",
    "    \n",
    "    for seq,target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq,target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq,target])\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    lower=min(len(buys),len(sells))\n",
    "    \n",
    "    buys=buys[:lower]\n",
    "    sells=sells[:lower]\n",
    "    \n",
    "    sequential_data=buys+sells\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    x=[]\n",
    "    y=[]\n",
    "    \n",
    "    for seq,target in sequential_data:\n",
    "        x.append(seq)\n",
    "        y.append(target)\n",
    "        \n",
    "    return np.array(x),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y=preprocess_df(main_df)\n",
    "validation_x,validation_y=preprocess_df(validation_main_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 65962 validation: 3174\n",
      "Dont buys:32981 buys: 32981\n",
      "validation dont buys: 1587 buys: 1587\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys:{train_y.count(0)} buys: {train_y.count(1)}\")\n",
    "print(f\"validation dont buys: {validation_y.count(0)} buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "BATCH_SIZE=64\n",
    "NAME= f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65962 samples, validate on 3174 samples\n",
      "Epoch 1/10\n",
      "65962/65962 [==============================] - 542s 8ms/step - loss: 0.7239 - acc: 0.5181 - val_loss: 0.6922 - val_acc: 0.5325\n",
      "Epoch 2/10\n",
      "65962/65962 [==============================] - 571s 9ms/step - loss: 0.6891 - acc: 0.5399 - val_loss: 0.6870 - val_acc: 0.5491\n",
      "Epoch 3/10\n",
      "65962/65962 [==============================] - 629s 10ms/step - loss: 0.6834 - acc: 0.5589 - val_loss: 0.6829 - val_acc: 0.5580\n",
      "Epoch 4/10\n",
      "65962/65962 [==============================] - 557s 8ms/step - loss: 0.6802 - acc: 0.5680 - val_loss: 0.6797 - val_acc: 0.5646\n",
      "Epoch 5/10\n",
      "65962/65962 [==============================] - 488s 7ms/step - loss: 0.6787 - acc: 0.5691 - val_loss: 0.6810 - val_acc: 0.5630\n",
      "Epoch 6/10\n",
      "65962/65962 [==============================] - 532s 8ms/step - loss: 0.6769 - acc: 0.5748 - val_loss: 0.6796 - val_acc: 0.5677\n",
      "Epoch 7/10\n",
      "65962/65962 [==============================] - 559s 8ms/step - loss: 0.6734 - acc: 0.5812 - val_loss: 0.6808 - val_acc: 0.5599\n",
      "Epoch 8/10\n",
      "65962/65962 [==============================] - 549s 8ms/step - loss: 0.6703 - acc: 0.5877 - val_loss: 0.6874 - val_acc: 0.5662\n",
      "Epoch 9/10\n",
      "65962/65962 [==============================] - 548s 8ms/step - loss: 0.6641 - acc: 0.5981 - val_loss: 0.7105 - val_acc: 0.5558\n",
      "Epoch 10/10\n",
      "65962/65962 [==============================] - 529s 8ms/step - loss: 0.6556 - acc: 0.6120 - val_loss: 0.6947 - val_acc: 0.5677\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(128,input_shape=(train_x.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128,input_shape=(train_x.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128,input_shape=(train_x.shape[1:])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "tensorboard= TensorBoard(log_dir=f'log/{NAME}')\n",
    "\n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
    "\n",
    "history=model.fit(\n",
    "    train_x,train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x,validation_y),\n",
    "    callbacks=[tensorboard,checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
